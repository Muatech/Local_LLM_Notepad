# Local_LLM_Notepad
Run a modern LLM anywhere with a double‑click. 

Local_LLM_Notepad is an offline plug-and-play app for running local large-language model. Drop the single bundled .exe onto a USB stick, walk up to any computer, and start chatting, brainstorming, or drafting documents. No installation, no internet, no admin rights required. 

# Why you’ll love it

🔌 Portable

Drop the one‑file EXE and your .gguf model onto a flash drive; run on any Windows PC without admin rights.

🪶 Clean UI

Two‑pane layout: type prompts below, watch token‑streamed answers above—no extra chrome.

🔍 Source‑word under‑lining

Every word or number you wrote in your prompt is automatically bold‑underlined in the model’s reply. Ctrl+left click on them to view them in a separate window. Handy for fact‑checking summaries, tables, or data extractions.

💾 Save/Load chats

One‑click JSON export keeps conversations with the model portable alongside the EXE.

⚡ Llama.cpp inside

CPU‑only by default for max compatibility.

🎹 Hot‑keys

Ctrl + S to send, Ctrl + Z to stop, Ctrl + F to find, Ctrl + Mouse‑Wheel zoom, etc.


# Quick Start

Download Local_LLM_Notepad-portable.exe from the Releases page.

Copy the EXE and a compatible GGUF model (e.g. gemma-3-1b-it-Q4_K_M.gguf) onto your USB.

Double‑click the EXE on any Windows computer. First launch caches the model into RAM; subsequent prompts stream instantly.

Need another model? Use File ▸ Select Model… and point to a different GGUF.(Feel free to keep multiple models in the same folder—LLM Notepad remembers your last pick.)




